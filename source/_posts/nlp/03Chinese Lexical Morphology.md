---
title: 03Chinese Lexical Morphology
date: 2022-04-08 11:25:09
tags: [NLP, 汉语词形态分析, 分词, 切分]
categories: NLP
---

# 汉语词形态分析

[toc]

## 汉语切分基础

回顾词形态分析的两个基本任务：

- 外部：**断词**——确定词的外部边界
- 内部：**词形还原**——内部结构分析

汉语是独立语，主要在于断词，即汉语切分/分词。词性还原基本没有。

## 汉语切分任务说明

- 关于汉语的词的定义/看法：大方之家们各持己见
- ··································································由”词“到”切分单元“：汉语切分而非汉语切词
- 不同的切分标注：反映在各自的切分数据上

## 汉语切分的两个主要难点问题

1. 边界歧义（Boundary Ambiguity）：从哪里切分

   1. 交集歧义（Overlap ambiguity: OA）：XJ/Y/ and X/JY/

      检测：通过FMM(正向)和BMM(负向)最大匹配算法。链长为奇数(A**B**C,A**BCD**E)的两者切分结果不同，可基于此检测到歧义；链长为偶数(A**BC**D)，结果相同，检测不出

   2. 组合歧义（Combination ambiguity: CA）：X/Y/ and XY/，即 X、Y、XY都是词典中的词

   3. 还有 混合歧义 真实歧义 伪歧义

2. 未登录词（Out of Vocabulary: OOV）（Unknow words）：词典/训练数据中没有此切分单元

   1. 如：派生词、命名实体、新词
   2. 边界歧义常与OOV混合出现

## 朴素的切分算法——基于规则

### 前向最大匹配算法 FMM

forward maximum match

早期一个朴素的切分算法，基于词表

> 例：
>
> 算法参数：最大匹配长度 MaxLen = 3
>
> 切分句子：语言学很重要
>
> 过程：取”语言学“查词表，在其中，ok；取”很重要”，不在词表中；取“很重”，不在；取“很”，不在，但是只有一个字，ok；取“重要“，在，ok

算法影响因素：

- MaxLen：太小，不能切对长的词；太大，经常回退；合适的=词表的平均词长+1/+2
- 词典

性能评估：

- 评测数据（带有标准答案的数据）

- 评测指标：常用 P/R/F1

  ![image-20220408112949364](https://cimgioc.oss-cn-beijing.aliyuncs.com/image-20220408112949364.png)

### 后向最大匹配算法 BMM

backward maximum match

### 基于规则的切分方法总结

FMM BMM

简单快速，可以用来发现OA

不能提供高质量的切分，没有进行不同切分选择的消歧能力：

- OA：总是切分成 XJ/Y（而BMM总是切分成 X/JY，所以用他俩可以检测歧义
- CA：总是把XY切分为一个词
- OOV：不能处理，一般切成单个字（也可提供某种信息）

扩展以处理歧义：

- 指定一些规则的方法：太麻烦，有例外

FMM/BMM切分使用的知识是词表，而消歧需要的是上下文信息，那么如何将上下文信息引入切分？

## 基于分类的切分

在每个位置上进行二分类，将切分问题转化为一系列二分类问题

需要已经切分好的数据来训练分类模型

优势：

- 已有各种监督分类器：NB、KNN、MaxEnt、DNN···
- 很多分类器可以使用更多的上下文信息

越细粒度的特征区分能力越强，NB不能利用更多的细粒度特征，MaxEnt能利用细粒度特征

人工设计特征，又陷入了特征工程。。。近年来基于**深度学习的表示学习能力**，采用深度学习模型来自动学习表示（特征）

- 向量词表示
- n-gram表示
- 多层次抽象表示

缺点：按次序进行二分类决策，一旦前面错误就会影响后面

改进：

- 联合决策，多个分类联合进行，各局部最优，全局最优
- 基于序列标注方法的切分

## ★★★基于序标的切分★★★

设计标签集，给每个字打标签，这样，联合分类转化为序列标注，切分就是找最优标注序列

序列标注模型：

- HMM 隐马尔科夫模型 只能利用较少的语言知识
- MEMM 极大熵马尔可夫模型 可以用更多特征，综合更多语言知识，但存在模型偏置
- CRF 条件随机场 可以使用更位丰富的特征

在**深度学习模型**用于序标**之前**，研究焦点集中在**特征设计**上，通过不断**挖掘新的特征**来提升切分性能。

2010年SIGHAN评测中某系统在各领域的成绩，文学领域最佳，其他领域非最佳。**没有系统在所有领域最佳**

2015年之后，**深度学习**给切分技术带来了深刻的影响，和分类任务一样，从**特征工程**转变为**由深层神经网络自动提取表示**

之后RNN模型的使用，以及在多层神经网络之上再叠加CRF层进行序标，进一步提升了切分的性能

虽然也有某些研究认为无需叠加CRF，只需要简单的softmax分类器，因为下面的多层表示抽象已经学习到足够丰富的信息了

但是目前的序标模型还是普遍**叠加CRF层**进行序标

课程在后面会逐步引出这些序列标注模型的具体细节

## 问题与分析

对汉语切分中的歧义问题有比较清楚的认识和较好的解决办法

但是**未登录词(OOV)**问题依然严峻，还有相关的数据稀疏问题、领域适应问题等

讨论：汉语切分**是否必要**？

- 其在机器翻译等四个NLP任务、以及情感极性判定任务的领域迁移任务上的结果都表明，直接基于字的模型比切分后的模型有更好的性能
- 认为可能的原因：切分后导致数据稀疏、OOV等问题

汉语词(上下)语言单元的多粒度性：目前确实很多高层NLP任务都可以直接基于字进行，但是也存在一些NLP任务本身就要基于词，同时也有比词大的切分单元需要显式获得

**命名实体识别**(NER，NE Recognition)：不仅找到NE的边界，还要判定这是什么实体 √ 更有用

准确识别命名实体在实际应用中具有关键性作用，NER成为独立于切分的NLP研究重点

NER方法：

- 基于规则的方法
- 数据驱动的方法
- 基于序列标注的方法

> Tip：序列标注模型是语言处理中的重要模型，通过为序列 标注模型设计不同的标签集，模型可以用来完成很多表面 上看起来和序列标注(序标)不太相关的任务
>
> 课程后面将从词性标注任务开始较为系统地介绍序列标注模型

NER研究重点和难点：（也是自然语言处理其他任务的共性难点）

- 当已有一定规模的标注数据时，NER性能在该任务上可用
- 当前NER的研究重点（因为不可能每出现一个新领域或一类新实体就去为之标大规模数据）
  - 跨领域、跨实体类型的NER
  - 小(无)数据的NER如何在缺少标注数据的新领域、新实体类型上构建较好的NER

